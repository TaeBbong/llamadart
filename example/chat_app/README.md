# llama_dart Chat Example

A Flutter chat application demonstrating real-world usage of llama_dart with UI.

## Features

- ðŸ¦™ Real-time chat with local LLM
- ðŸ“± Material Design 3 UI
- âš™ï¸ Model configuration (path, backend selection)
- ðŸ’¾ Settings persistence
- ðŸ”„ Streaming generation
- ðŸŽ¨ User and AI message bubbles

## Setup

### 1. Download a Model
```bash
# For macOS/Linux
mkdir -p /tmp/models
curl -L https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf \
  -o /tmp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf

# For Android
# Download and place in /storage/emulated/0/Download/
```

### 2. Run the App
```bash
cd chat_app
flutter pub get
flutter run
```

### 3. Configure
1. Tap the settings icon (âš™ï¸) in the app bar
2. Set your model path
3. Select Preferred Backend (Auto/Metal/Vulkan/CPU)
4. Tap "Load Model"
5. Start chatting!

## Testing Scenarios

### Scenario 1: Fresh Install
1. Install the app
2. Model not loaded -> Show welcome screen
3. Configure and load model
4. Verify it works

### Scenario 2: App Restart
1. Load model and chat
2. Close and reopen app
3. Verify settings persist
4. Verify model reloads automatically

### Scenario 3: Offline Mode
1. Use app once (downloads libraries)
2. Disconnect internet
3. Restart app
4. Verify it works offline

### Scenario 4: Multiple Messages
1. Load model
2. Send multiple messages
3. Verify responses
4. Check context is maintained

## Architecture

The app follows a clean architecture with state management:

```
lib/
â”œâ”€â”€ main.dart              # App entry point
â”œâ”€â”€ chat_screen.dart       # UI implementation
â””â”€â”€ models/
    â””â”€â”€ chat_model.dart    # State management + business logic
```

### ChatProvider
State management provider using `ChangeNotifier`:
- Manages model lifecycle (load/unload)
- Handles chat messages
- Persists settings to SharedPreferences
- Provides reactive UI updates

### ChatScreen
Flutter UI with Material Design 3:
- Message list with scroll-to-bottom
- Input field with send button
- Settings modal for model configuration
- Loading and error states

## Code Examples

### Loading a Model
```dart
final model = await LlamaModel.loadFromFile(
  modelPath,
   params: DartLlamaModelParams(
     nGpuLayers: 999, // Offload all layers for best performance on GPU
     useMmap: true,
   ),
);

final context = model.createContext(
  params: DartLlamaContextParams(
    nCtx: 2048,
    nThreads: 4,
  ),
);
```

### Sending a Message
```dart
final stream = context.generate(
  prompt: userMessage,
  maxTokens: 128,
);

final response = await stream.join();
```

### Persisting Settings
```dart
final prefs = await SharedPreferences.getInstance();
await prefs.setString('model_path', modelPath);
await prefs.setString('model_path', modelPath);
await prefs.setInt('preferred_backend', backendIndex);
```

## Screenshots

_(Add screenshots here when complete)_

## Troubleshooting

**"Failed to load library" on first run:**
- Check console for download messages
- Ensure GitHub releases are accessible
- Check internet connection

**"Model file not found" error:**
- Verify model path in settings
- Ensure model is downloaded
- Check file permissions

**Slow generation:**
- Ensure hardware acceleration is enabled in settings
- Use smaller quantization model (Q4_K_M)

**App crashes on startup:**
- Check console output for error messages
- Verify llama_dart dependency is correctly configured
- Ensure Flutter version >= 3.10.0

## Tech Stack

- **llama_dart** - LLM inference
- **Provider** - State management
- **shared_preferences** - Settings persistence
- **Material Design 3** - UI components

## Platform Support

| Platform | Status | Notes |
|----------|--------|-------|
| macOS    | âœ… Tested | Full support |
| Linux    | âœ… Tested | Full support |
| Windows  | ðŸŸ¡ Expected | Should work |
| Android  | âœ… Verified | Full Vulkan acceleration |
| iOS      | âœ… Verified | Full Metal acceleration |

## Future Enhancements

- [ ] Conversation history
- [ ] Multiple model support
- [ ] Export/import conversations
- [ ] Streaming token display in UI
- [ ] Custom system prompts
- [ ] Temperature/top_p controls in UI
- [ ] Dark mode theme
